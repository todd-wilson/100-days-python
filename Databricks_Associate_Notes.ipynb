{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOck5qlbPrgmq57sGiGLXKi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Databricks\n",
        "Multi-cloud Lakehouse Platform base on Apache Spark. A Lakehouse is a unified analytics platform which combines the best elements of a data warehouse and data lake. It is one platform that unifies data engineering, analytics and AI workloads.\n",
        "\n",
        "## Data Lake\n",
        "* Open, flexible with ML support\n",
        "\n",
        "## Data warehouse\n",
        "* Reliable, performative, with strong governance.\n",
        "\n",
        "# Databricks Lakehouse Platform.\n",
        "* Clouse Service - Runs on AWS, Azure and Google Cloud\n",
        "* Runtime - Spark and Delta Lake\n",
        "* Workspace - Data Engineering, Data Warehousing and Machine Learning\n",
        "\n",
        "## Control Plane (Databricks Account)\n",
        "* Web UI, Cluster Management, Workflows and Notebooks.\n",
        "\n",
        "## Data Plane (Customer Account)\n",
        "* Cluster VMs and Storage (DBFS)\n",
        "\n",
        "## Spark on Databricks\n",
        "* In-memory, distributed data processing.\n",
        "* Supports Scala, Python, SQL, R and Java\n",
        "* Support batch and stream processing\n",
        "* Support structured, semi and unstructured data\n",
        "\n",
        "## DBFS (Databricks File System)\n",
        "* Distributed File System\n",
        "* Comes pre-installed on the cluster\n",
        "* Abstraction layer (data is persisted in underlying cloud storage)\n",
        "\n",
        "## Cluster\n",
        "A set of computers of nodes working together like a single entity.\n",
        "* Master Node (Driver)\n",
        "  * Coordinates the workers and their parallel execution of tasks.\n",
        "* Worker Nodes\n",
        "\n"
      ],
      "metadata": {
        "id": "zX-mcJkiibLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Delta Lake\n",
        "Delta Lake is an open-source storage framework which brings reliability to data lakes.\n",
        "\n",
        "Is|Is Not\n",
        "-|-\n",
        "Open-source | Proprietary Technology\n",
        "Storage framework/layer | Storage format/medium\n",
        "Enabling building Lakehouse | Data warehouse / Database service\n",
        "\n",
        "## Transaction log (Delta log)\n",
        "* The _delta_log is stored in JSON format\n",
        "  * 000.json, 001.json, 002.json\n",
        "  * Ordered records of every transaction performed on the table\n",
        "  * JSON file contains commit information\n",
        "  * Operations performed and predicates used\n",
        "  * Data files affected (added/removed)\n",
        "* The data files are store in parquet format\n",
        "\n",
        "The transaction log is the single source of truth for your data.\n",
        "\n",
        "\n",
        "## Delta Lake Advantages\n",
        "* Brings ACID transactions to object storage\n",
        "* Provides scalable metadata\n",
        "* Full audit trail of all changes\n"
      ],
      "metadata": {
        "id": "aLjupraSmPlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Magic Commands\n",
        "* %fs\n",
        "* %md\n",
        "* %sql\n",
        "* %python"
      ],
      "metadata": {
        "id": "nmYHOv-h1QiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TABLES\n",
        "## CREATE TABLE\n",
        "```sql\n",
        "CREATE TABLE employees\n",
        "--USING DELTA\n",
        "(id INT, name STRING, salary DOUBLE)\n",
        "```\n",
        "* Requires a manual schema declaration\n",
        "* Needs an INSERT to insert data.\n",
        "* Using Delta is optional as all tables are delta tables by default on Databricks.\n",
        "* Tables are created and can be viewed in the Data tab using the Catalog explorer.\n",
        "\n",
        "## CREATE TABLE AS\n",
        "* Data is inserted automatically from source table.\n",
        "* Schema information is automatically inferred.\n",
        "```sql\n",
        "CREATE TABLE\n",
        "COMMENT \"Enter a comment\"\n",
        "PARTITIONED BY (col1, col2)\n",
        "LOCATION '/custom/path/'\n",
        "AS\n",
        "```\n",
        "## IF NOT EXISTS\n",
        "```sql\n",
        "CREATE TABLE IF NOT EXISTS table-name\n",
        "```\n",
        "## Table Constraint\n",
        "* Two types\n",
        " * NOT NULL\n",
        " * CHECK\n",
        "```sql\n",
        "ALTER TABLE\n",
        "```\n",
        "## Deep Clone\n",
        "* Copies data and metadata.\n",
        "```sql\n",
        "CREATE TABLE table-name\n",
        "DEEP CLONE source-table\n",
        "```\n",
        "* Can sync changes between the source and target table. So changes can happen incrementally.\n",
        "* Large datasets can take a long time.\n",
        "* Data modifications will not affect source table.\n",
        "## Shallow Clone\n",
        "* Copies only metadata. No data is moved.\n",
        "* Good for testing changes to new table without modifying the original table.\n",
        "* Data modifications will not affect source table.\n",
        "```sql\n",
        "CREATE TABLE table-name\n",
        "SHALLOW CLONE source-table\n",
        "```\n",
        "## INSERT INTO\n",
        "Records are inserted in parallel depending on the number of cores you are using. If you have 4 cores and 4 records to INSERT then you should see 4 files.\n",
        "\n"
      ],
      "metadata": {
        "id": "T8SbgaUwpIav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Views\n",
        "* Queries the source tables defined in the view, but does not have any data of it's own.\n",
        "* Types\n",
        "  * Stored Views\n",
        "    * Persisted in the database\n",
        "    * CREATE VIEW view-name AS query\n",
        "  * Temporary View\n",
        "    * Dropped when the session ends.\n",
        "      * Spark session is create when opening a notebook, attaching a re-attaching a notebook, installing a python package, restarting cluster.\n",
        "    * CREATE TEMP VIEW view-name as query\n",
        "  * Global Temporary View\n",
        "    * Tied to the cluster\n",
        "      * Persists until dropped or cluster stops.\n",
        "    * CREATE GLOBAL TEMP VIEW view-name AS\n",
        "      * SELECT * FROM global_temp view-name"
      ],
      "metadata": {
        "id": "QpiiQXoA3jlQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metadata\n",
        "## DESCRIBE DETAILS\n",
        "Let's us look at table Metadata.\n",
        "* Use DESCRIBE EXTENDED to see location information or if table is managed.\n",
        "* Use DESCRIBE DATABASE EXTENDED to see database information.\n",
        "\n",
        "## DESCRIBE HISTORY\n",
        "Shows all operations performed on the table.\n",
        "\n",
        "## SHOW\n",
        "* SHOW TABLE IN database-name\n",
        "* SHOW TABLE IN global_temp;"
      ],
      "metadata": {
        "id": "A_gsqrJD3gRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Travel\n",
        "Audit data changes\n",
        "Use DESCRIBE HISTORY to look at changes.\n",
        "\n",
        "* Use a timestamp\n",
        "TIMESTAMP AS OF \"timestamp\"\n",
        "* Use a version\n",
        "VERSION AS OF <number>\n",
        "<table>@v<number>\n",
        "\n",
        "## RESTORE TABLE\n"
      ],
      "metadata": {
        "id": "oP7XbFdjrDOK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OPTIMIZE\n",
        "* Compacts small files into larger files to improve performance.\n",
        "* ZORDER BY column_name\n",
        "  * Sorts data and notes the begin and end in each file (doesn't have to look through all files)."
      ],
      "metadata": {
        "id": "qKUufHbSrC4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vacuum Command\n",
        "* Cleans up uncommited files and files that are not in the latest table.\n",
        "* VACUUM table_name [retention period]\n",
        "  * Default retention is 7 days.\n",
        "\n",
        "**Once you run VACUUM you can no longer time travel past the retention period as the files no longer exist!**\n",
        "\n",
        "Get past the rentention period by using:\n",
        "VACUUM table_name RETAIN 0 HOURS\n",
        "SET spark.databricks.delta.retentionDurationCheck = false;\n",
        "\n",
        "Command will work now, but do not do it in production.\n",
        "\n"
      ],
      "metadata": {
        "id": "GmGtS1UJrM0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relational Entities\n",
        "## Databases\n",
        "* Schema in Hive metastore. Can use CREATE DATABASE or CREATE SCHEMA.\n",
        "  * The Hive metastore stores metadata about yoru data warehouse.\n",
        "  * Every workspace has a default database in the Hive metastore.\n",
        "  * Default database location: dbfs:/user/hive/warehouse\n",
        "  * Default database\n",
        "    * dbfs:/user/hive/warehouse/table-1\n",
        "  * Other databases created\n",
        "    * dbfs:/user/hive/warehouse/custom-db-name.db/table-1\n",
        "### Custom Database\n",
        "* dbfs:/custom/path/to/db/custom-db-name.db/table-1\n",
        "\n",
        "## Tables\n",
        "* Two types of Tables\n",
        "  * Managed Tables\n",
        "    * Table created under default database.\n",
        "    * Databricks manages so when you delete a table the underlying data is removed.\n",
        "  * External Tables\n",
        "    * Table created outside the database directory.\n",
        "    * Use CREATE TABLE LOCATION 'path'\n",
        "    * Databricks does not manage so when you delete a table the underlying data is NOT removed.\n",
        "## Location Keyword\n",
        "  * This is where the data files are located.\n",
        "  * You can have external tables in the default database.\n",
        "  * USE database; will let you create your table in any database you want to.\n",
        "```sql\n",
        "  USE DATABASE\n",
        "  CREATE TABLE\n",
        "  LOCATION 'path'\n",
        "```"
      ],
      "metadata": {
        "id": "ujd1gtxYrMyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Querying Files\n",
        "* SELECT\n",
        "```sql\n",
        "SELECT *\n",
        "FROM file_format.`/file/path/file-name`\n",
        "```\n",
        "  * SELECT is good for self-describing formats (formats that contain metadata) like json and parquet.\n",
        "  * Not good for csv, tsv, customer delimiter.\n",
        "\n",
        "* Wildcards\n",
        "  * Use wildcards to query multiple files\n",
        "    * file_*.txt\n",
        "* Raw data extract\n",
        "  *file_format\n",
        "    * Text\n",
        "      * JSON, CSV, TSV, TXT\n",
        "        * Use text as file_format\n",
        "        * Useful if corrupted\n",
        "    * Binary\n",
        "      * Use binaryFile as file_format\n",
        "* CREATE TABLE from a file\n",
        "  * USE CTAS statement\n",
        "  * Useful for data with defined schemas.\n",
        "  * Does not support any file options.\n",
        "* CREATE TABLE table_name USING\n",
        "```sql\n",
        "CREATE TABLE table_name\n",
        "(schema)\n",
        "USING data_source\n",
        "OPTIONS(key1=val1,...)\n",
        "LOCATION = 'path'\n",
        "```\n",
        "  * USING can be JDBC, CSV and others.\n",
        "  * Always creates an external table\n",
        "  * The table is **NON-DELTA** table so it is not a managed table.\n",
        "      * **Solution is to create a TEMP VIEW and then use CTAS statement on TEMP VIEW to create the table.***\n",
        "\n",
        "    \n",
        "  "
      ],
      "metadata": {
        "id": "F0jHyA6wrMwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W4OO6q2arMtf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NJ1huozArMrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ArNw-3QJrMon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JQb7XjFBrMmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HYEgSkgHrMkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MNyxJ3ISrMiF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1p6X-St6rMf2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9VFCGUwnrMds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JNn-AEqIrMbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0Qm6UBxhrMZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KnX9QCeFrMWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g5amzP9wrMPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YoILAnDprL33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0Hv6eO2QrLRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qmi89kJ2rKbA"
      }
    }
  ]
}